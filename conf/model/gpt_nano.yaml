defaults:
  - _self_

dataloader:
  _target_: torch.utils.data.DataLoader
  batch_size: 6
  num_workers: 5
  prefetch_factor: 2
  dataset:
    _target_: src.training.datasets.main_dataset.MainDataset
    p_augment: 0.2
    block_size: 128
    augmentation:
      _target_: src.training.augments.bert_augment.BertAugment
      p_bert: 0.2
      block_size: 512

torch_trainer:
  _target_: src.training.main_trainer.MainTrainer
  epochs: 80
  patience: 80
  learning_rate: 6e-4
  save_model: False
  scheduler_param:
    t_initial: 40
    warmup_t: 1
    warmup_lr_init: 1e-5
  model:
    _target_: src.training.models.gpt_model.GPT
    vocab_size: 50304
    n_embedding: 192
    block_size: 128
    n_layer: 12
    n_head: 12
    dropout: 0.2
    bias: True
    kv_heads: 4
    grouped: True